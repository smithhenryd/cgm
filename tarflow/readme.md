# Tarflow Experiments
To reproduce our code for fine-tuning TarFlow, follow these steps:

1. Install `wandb`, `openai`, `torchvision`, `torchmetrics` in your environment
```
mamba install -c conda-forge wandb openai torchvision torchmetrics
```

2. Set your OpenAI API key as an environment variable. 

This key will be used to make queries to ChatGPT. See https://openai.com/api/. 

Set the key for a single session using
```
export OPENAI_API_KEY="your_key_here"
```
or permanently using 
```
echo 'export OPENAI_API_KEY="your_key_here"' >> ~/.bashrc
source ~/.bashrc
```

3. Retrieve the tarflow checkpoint from https://ml-site.cdn-apple.com/models/tarflow/afhq256/afhq_model_8_768_8_8_0.07.pth. 
Move it into the subdirectory `models`. 

4. To perform CGM fine-tuning, run
```
python calibrate_tarflow.py \
  --path models/afhq_model_8_768_8_8_0.07.pth \
  --calibration_mode relax \
  --lambda 0.0001 \
  --epochs 50 \
  --N_samples 50000 \
  --ckpt_every 50 
```
This will write `N_samples` output images to the directory `tarflow_outputs`. The default is 50k, which is the number used to compute FID.
It will also save a checkpoint of the tarflow model every 50 epochs to the directory `checkpoints`.

5. To run FID evals,

i. Download the AFHQ dataset from the [stargan-v2 GitHub repository (Choi et al., 2020)](https://github.com/clovaai/stargan-v2/tree/master). For the calibration task described in the paper, only the wildlife class is necessary.

ii. Move all samples (generated by the base/fine-tuned tarflow model) on which to compute FID into a subdirectory `wild` e.g., `my_samples/wild`. If the directory is empty, the model will first generate samples.

iii. Compute FID by calling, for example, 
```
python compute_fid.py \
  --afhq_root stargan-v2/data/afhq \
  --split train \
  --out_fake_dir my_samples \
  --weight_dict weight_dict_afhq.pt
```
`weight_dict_afhq.pt` contains annotations of the AFHQ train dataset from GPT-o5 mini. When evaluating the FID on samples from the fine-tuned model, these annotations are used to reweight the train samples to balance the proportions of animals belonging to each class. If `weight_dict` is `None`, then no reweighting is performed (i.e., the original AFHQ train dataset is used).
